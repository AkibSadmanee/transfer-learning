{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Lexicon and pre-trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\Datasets\\Embeddings\\GoogleNews-vectors-negative300.bin\n",
      "F:\\Datasets\\Embeddings\\word2vec_dim300_win5_iter35.model\n",
      "F:\\Datasets\\Embeddings\\bn-en.txt\n"
     ]
    }
   ],
   "source": [
    "from os import path\n",
    "filepath = \"F:\\\\Datasets\\\\Embeddings\"\n",
    "en_embedding_filename = \"GoogleNews-vectors-negative300.bin\"\n",
    "bn_embedding_filename = \"word2vec_dim300_win5_iter35.model\"\n",
    "lexicon_filename = \"bn-en.txt\"\n",
    "\n",
    "en_embedding_path = path.join(filepath, en_embedding_filename)\n",
    "bn_embedding_path = path.join(filepath, bn_embedding_filename)\n",
    "lexicon_path = path.join(filepath, lexicon_filename)\n",
    "\n",
    "print(en_embedding_path)\n",
    "print(bn_embedding_path)\n",
    "print(lexicon_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EN: Loaded Successlly.\n",
      "BN: Loaded Successlly.\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "#Load models\n",
    "en_model = KeyedVectors.load_word2vec_format(en_embedding_path, binary=True)\n",
    "bn_model = Word2Vec.load(bn_embedding_path)\n",
    "\n",
    "#Check if Models are loaded successfully\n",
    "try:\n",
    "    en_model.vocab[\"school\"]\n",
    "except:\n",
    "    print(\"EN: Word not fond.\")\n",
    "else:\n",
    "    print(\"EN: Loaded Successlly.\")\n",
    "    \n",
    "try:\n",
    "    bn_model.wv.vocab[\"আমি\"]\n",
    "except:\n",
    "    print(\"BN: Word not fond.\") \n",
    "else:\n",
    "    print(\"BN: Loaded Successlly.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64497, ['মানবজাতি', 'mankind'], ['কেশ', 'hairstyle'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check for English in the Translated section\n",
    "import re\n",
    "pattern = r\"[a-zA-Z]*\"\n",
    "\n",
    "lexicon = []\n",
    "with open(lexicon_path, \"r\", encoding=\"utf-8\") as fr:\n",
    "    for row in fr:\n",
    "        row = row.replace(\"\\n\", \"\")\n",
    "        row = row.split()\n",
    "\n",
    "        lexicon.append(row)\n",
    "len(lexicon), lexicon[0], lexicon[-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper function for creating embeddings with Lexicon-words\n",
    "def get_embedding(bn_word, bn_model, en_word, en_model):\n",
    "    try:\n",
    "        bn_model.wv.vocab[bn_word]\n",
    "        en_model.vocab[en_word]\n",
    "    except:\n",
    "        return []\n",
    "    else:\n",
    "        return (en_model[en_word], bn_model.wv[bn_word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((52752, 300), (52752, 300))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create 2 different embeddings for Bangla and English\n",
    "#that contain only the words available in the lexicon\n",
    "import numpy as np\n",
    "en_embedding_D = []\n",
    "bn_embedding_D = []\n",
    "\n",
    "for pair in lexicon:\n",
    "    try:\n",
    "        bn,en = get_embedding(pair[0],bn_model, pair[1],en_model)\n",
    "    except:\n",
    "        continue\n",
    "    else:\n",
    "        en_embedding_D.append(en)\n",
    "        bn_embedding_D.append(bn)\n",
    "\n",
    "en_embedding_D = np.array(en_embedding_D)\n",
    "bn_embedding_D = np.array(bn_embedding_D)\n",
    "en_embedding_D.shape , bn_embedding_D.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corpus Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 300) (300,) (300, 300)\n"
     ]
    }
   ],
   "source": [
    "#Calculae SVD of the Lexicon-embeddings\n",
    "from numpy.linalg import svd\n",
    "from numpy import transpose as T\n",
    "from numpy import dot\n",
    "\n",
    "# Y_D^T * X_D\n",
    "# Y_D = English Embeddings ; X_D = Bangla Embeddings\n",
    "YDT_XD = en_embedding_D.T.dot(bn_embedding_D)\n",
    "\n",
    "u, s, vh = np.linalg.svd(YDT_XD, full_matrices=True)\n",
    "V = vh.T\n",
    "print(u.shape, s.shape, V.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000000, 1337032)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(en_model.vocab), len(bn_model.wv.vocab) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert gensim English model to numpy array\n",
    "en_vocab_size = 3000000\n",
    "i = 0\n",
    "\n",
    "Y = np.zeros((en_vocab_size,300),dtype='float32')\n",
    "\n",
    "for k,v in en_model.vocab.items():\n",
    "    Y[i] = en_model[k]\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert gensim Bangla model to numpy array\n",
    "bn_vocab_size = 1337032\n",
    "i = 0\n",
    "\n",
    "X = np.zeros((bn_vocab_size,300),dtype='float32')\n",
    "\n",
    "for k,v in bn_model.wv.vocab.items():\n",
    "    X[i] = bn_model.wv[k]\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1337032, 300), (3000000, 300))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transform our Embeddings on both languages with u and vh\n",
    "trans_bn_emb = X.dot(u)\n",
    "trans_en_emb = Y.dot(V)\n",
    "\n",
    "trans_bn_emb.shape, trans_en_emb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load English Sentiment Data - IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "datapath = \"F:\\\\Datasets\\\\Sentiment\\\\aclImdb\\\\train\"\n",
    "pos_path = path.join(datapath, \"pos\")\n",
    "neg_path = path.join(datapath, \"neg\")\n",
    "unsup_path = path.join(datapath, \"unsup\")\n",
    "\n",
    "pos_files = listdir(pos_path)\n",
    "neg_files = listdir(neg_path)\n",
    "unsup_files = listdir(unsup_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12500"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_reviews = []\n",
    "for pos_file in pos_files:\n",
    "    pos = path.join(pos_path, pos_file)\n",
    "    with open(pos, \"r\", encoding=\"utf-8\") as fr:\n",
    "        pos_reviews.append(fr.read())\n",
    "len(pos_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as \"Teachers\". My 35 years in the teaching profession lead me to believe that Bromwell High's satire is much closer to reality than is \"Teachers\". The scramble to survive financially, the insightful students who can see right through their pathetic teachers' pomp, the pettiness of the whole situation, all remind me of the schools I knew and their students. When I saw the episode in which a student repeatedly tried to burn down the school, I immediately recalled ......... at .......... High. A classic line: INSPECTOR: I'm here to sack one of your teachers. STUDENT: Welcome to Bromwell High. I expect that many adults of my age think that Bromwell High is far fetched. What a pity that it isn't!\n"
     ]
    }
   ],
   "source": [
    "print(pos_reviews[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12500"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_reviews = []\n",
    "for neg_file in neg_files:\n",
    "    neg = path.join(neg_path, neg_file)\n",
    "    with open(neg, \"r\", encoding=\"utf-8\") as fr:\n",
    "        neg_reviews.append(fr.read())\n",
    "len(neg_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story of a man who has unnatural feelings for a pig. Starts out with a opening scene that is a terrific example of absurd comedy. A formal orchestra audience is turned into an insane, violent mob by the crazy chantings of it's singers. Unfortunately it stays absurd the WHOLE time with no general narrative eventually making it just too off putting. Even those from the era should be turned off. The cryptic dialogue would make Shakespeare seem easy to a third grader. On a technical level it's better than you might think with some good cinematography by future great Vilmos Zsigmond. Future stars Sally Kirkland and Frederic Forrest can be seen briefly.\n"
     ]
    }
   ],
   "source": [
    "print(neg_reviews[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unsup_reviews = []\n",
    "for unsup_file in unsup_files:\n",
    "    unsup = path.join(unsup_path, unsup_file)\n",
    "    with open(unsup, \"r\", encoding=\"utf-8\") as fr:\n",
    "        unsup_reviews.append(fr.read())\n",
    "len(unsup_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I admit, the great majority of films released before say 1933 are just not for me. Of the dozen or so \"major\" silents I have viewed, one I loved (The Crowd), and two were very good (The Last Command and City Lights, that latter Chaplin circa 1931).<br /><br />So I was apprehensive about this one, and humor is often difficult to appreciate (uh, enjoy) decades later. I did like the lead actors, but thought little of the film.<br /><br />One intriguing sequence. Early on, the guys are supposed to get \"de-loused\" and for about three minutes, fully dressed, do some schtick. In the background, perhaps three dozen men pass by, all naked, white and black (WWI ?), and for most, their butts, part or full backside, are shown. Was this an early variation of beefcake courtesy of Howard Hughes?\n"
     ]
    }
   ],
   "source": [
    "print(unsup_reviews[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translate IMDB dataset English -> Bangla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\akibs\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "\n",
    "def find_bn_equivalent_embedding(word, en_model, trans_en_emb, trans_bn_emb):\n",
    "    try:\n",
    "        en_emb = trans_en_emb[en_model.vocab[word].index]\n",
    "    except:\n",
    "        return None, None\n",
    "    min_ind = 0\n",
    "    min_distance = 1\n",
    "    for i, bn_emb in enumerate(trans_bn_emb):\n",
    "        if spatial.distance.cosine(en_emb, bn_emb) < min_distance:\n",
    "            min_distance = spatial.distance.cosine(en_emb, bn_emb)\n",
    "            min_ind = i\n",
    "    return min_ind, trans_bn_emb[min_ind]\n",
    "\n",
    "def get_bn_word(ind, bn_model):\n",
    "    for key, val in bn_model.wv.vocab.items():\n",
    "        if val.index == ind:\n",
    "            return key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a, b = find_bn_equivalent_embedding(\"school\", en_model, trans_en_emb, trans_bn_emb)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bromwell  -  সংশয়াপন্ন\n",
      "High  -  কতটুকুর\n",
      "is  -  করুন\n",
      "cartoon  -  ট্রাইব্যুনালকে\n",
      "comedy  -  বৈপরীত্য\n",
      "It  -  অনাহারে\n",
      "ran  -  উপরওলার\n",
      "at  -  অস্বাভাবিকভাবেই\n",
      "the  -  মুখগুলিকে\n",
      "same  -  \"\n",
      "time  -  জাতিসঙ্ঘের\n",
      "as  -  লুকিয়ে\n",
      "some  -  পুলিশ\n",
      "other  -  দাবী\n",
      "programs  -  পূর্ববাংলার\n",
      "about  -  ভুলগুলো\n",
      "school  -  গায়\n",
      "life  -  উল্লেখযোগ্য\n",
      "such  -  শতাব্দী\n",
      "as  -  লুকিয়ে\n",
      "Teachers  -  উদ্বেগজনিত\n",
      "My  -  হঠাৎ\n",
      "years  -  বিচ্ছিন্নতাবাদীদের\n",
      "in  -  খেদমতের\n",
      "the  -  মুখগুলিকে\n",
      "teaching  -  বাসদ\n",
      "profession  -  ভাতা\n",
      "lead  -  বিজ্ঞপির\n",
      "me  -  রান\n",
      "believe  -  সহিত\n",
      "that  -  আপনাদের\n",
      "Bromwell  -  সংশয়াপন্ন\n",
      "High  -  কতটুকুর\n",
      "satire  -  সুজানাকে\n",
      "is  -  করুন\n",
      "much  -  হয়ঃ\n",
      "closer  -  দেশগুলোয়\n",
      "reality  -  দায়\n",
      "than  -  জানান\n",
      "is  -  করুন\n",
      "Teachers  -  উদ্বেগজনিত\n",
      "The  -  শিক্ষাভবনের\n",
      "scramble  -  খসরু\n",
      "survive  -  স্কেলে\n",
      "financially  -  সন্তুষ্টির\n",
      "the  -  মুখগুলিকে\n",
      "insightful  -  সিপিইউ\n",
      "students  -  বাস্তবায়নের\n",
      "who  -  জঙ্গিরাই\n",
      "can  -  পানি\n",
      "see  -  চুন\n",
      "right  -  বিশ্বপ্রেমিক\n",
      "through  -  বিভাবতীর\n",
      "their  -  টান\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "tokenized_text = nltk.word_tokenize(pos_reviews[0])\n",
    "for word in tokenized_text:\n",
    "    i, bn_emb = find_bn_equivalent_embedding(word, en_model, trans_en_emb, trans_bn_emb)\n",
    "    if i:\n",
    "        bn_word = get_bn_word(i, bn_model)\n",
    "        print(word, \" - \" ,bn_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "destination = \"F:\\\\Datasets\\\\Sentiment\\\\aclImdb_bn\"\n",
    "en_model.vocab[\"a\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "en_model.vocab[\"school\"].index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
